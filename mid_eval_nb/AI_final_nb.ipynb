{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **AI sem 4**\n",
        "# **NLP project**\n",
        "# **team members**\n",
        "\n",
        "\n",
        "*   **Naman Agarwal**\n",
        "*   **Mukund bihari gupta**\n",
        "\n",
        "*   **Nishant Mohan**\n",
        "*   **Prashant Kumar**\n",
        "\n",
        "*   **Naman Katiyar**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5xIvJjoGT6R1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GOAL**\n",
        "# So our main goal is to develop a humanized essay/story generator that can take up a prompt and based on it generate a short story that resembles a human written story"
      ],
      "metadata": {
        "id": "0AUsXpWuTh-V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP 1** -  Finding and processing the datsset\n"
      ],
      "metadata": {
        "id": "BcH3dT9wW7UE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# choosing dataset wisely is of great importance when it comes to NLP tasks because the context or the emotions or the language our model uses are all dependent on the dataset."
      ],
      "metadata": {
        "id": "cm-H6lGrXZBq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We are Using the writing propmts dataset from kaggle(link below)\n",
        "https://www.kaggle.com/datasets/ratthachat/writing-prompts\n",
        "\n",
        "# This dataset contains a huge corpus of human written essays over a wide variety of prompts it includes both formal and informal language and we found out to be suitable for our task"
      ],
      "metadata": {
        "id": "vuwwo1h2X_6V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4ea1694"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "af442642",
        "outputId": "694b0028-40cb-4679-8053-e61b44a9c418"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                  source  \\\n",
            "0      [ WP ] Leonardo DiCaprio in a fit of rage begi...   \n",
            "1      [ CW ] Kill the writer in first-person narrati...   \n",
            "2      [ EU ] Sean Bean has a hard time leaving his r...   \n",
            "3      [ WP ] A kid doodling in a math class accident...   \n",
            "4      [ WP ] As a Space marine you have an allowance...   \n",
            "...                                                  ...   \n",
            "15133  [ WP ] You are a devout christian , and you ju...   \n",
            "15134  [ WP ] Describe a universe where a personal st...   \n",
            "15135  [ WP ] Turning your girlfriend into a pumpkin ...   \n",
            "15136  [ WP ] God answers every time you call His nam...   \n",
            "15137  [ cw ] write about the strangest/scariest/sadd...   \n",
            "\n",
            "                                                  target  \n",
            "0      The wet marble floor pressed on his cheek like...  \n",
            "1      It 's been three days since my boyfriend pisse...  \n",
            "2      George fled . Not terrifically fast , not at h...  \n",
            "3      It was dark and Levi was pretty sure he was ly...  \n",
            "4      `` Hi dad ! '' <newline> <newline> The words s...  \n",
            "...                                                  ...  \n",
            "15133  Allen died choking on a ham sandwich . It was ...  \n",
            "15134  Usually he knew his number what it was by simp...  \n",
            "15135  There were several things wrong with this situ...  \n",
            "15136  `` Here , get in the back . '' You climbed int...  \n",
            "15137  The night was as thick and terrifying as any I...  \n",
            "\n",
            "[15138 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "with open('../Dataset/writingPrompts/test.wp_source', 'r') as file:\n",
        "    source_lines = file.readlines()\n",
        "with open('../Dataset/writingPrompts/test.wp_target', 'r') as file:\n",
        "    target_lines = file.readlines()\n",
        "\n",
        "df_source = pd.DataFrame(source_lines, columns=['source'])\n",
        "df_target = pd.DataFrame(target_lines, columns=['target'])\n",
        "\n",
        "df_merged = pd.concat([df_source, df_target], axis=1)\n",
        "\n",
        "df_merged.to_json('../PreProcessedDataset/test.json', orient='records', lines=True)\n",
        "\n",
        "print(df_merged)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26b65cdc",
        "outputId": "b2a02f75-8784-45f5-d466-acdc2f779b67"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[ WP ] Leonardo DiCaprio in a fit of rage begi...</td>\n",
              "      <td>The wet marble floor pressed on his cheek like...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[ CW ] Kill the writer in first-person narrati...</td>\n",
              "      <td>It 's been three days since my boyfriend pisse...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[ EU ] Sean Bean has a hard time leaving his r...</td>\n",
              "      <td>George fled . Not terrifically fast , not at h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[ WP ] A kid doodling in a math class accident...</td>\n",
              "      <td>It was dark and Levi was pretty sure he was ly...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[ WP ] As a Space marine you have an allowance...</td>\n",
              "      <td>`` Hi dad ! '' &lt;newline&gt; &lt;newline&gt; The words s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              source  \\\n",
              "0  [ WP ] Leonardo DiCaprio in a fit of rage begi...   \n",
              "1  [ CW ] Kill the writer in first-person narrati...   \n",
              "2  [ EU ] Sean Bean has a hard time leaving his r...   \n",
              "3  [ WP ] A kid doodling in a math class accident...   \n",
              "4  [ WP ] As a Space marine you have an allowance...   \n",
              "\n",
              "                                              target  \n",
              "0  The wet marble floor pressed on his cheek like...  \n",
              "1  It 's been three days since my boyfriend pisse...  \n",
              "2  George fled . Not terrifically fast , not at h...  \n",
              "3  It was dark and Levi was pretty sure he was ly...  \n",
              "4  `` Hi dad ! '' <newline> <newline> The words s...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df=pd.read_json('../PreProcessedDataset/test.json', lines=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59c0b5c6"
      },
      "outputs": [],
      "source": [
        "with open('../Dataset/writingPrompts/train.wp_source', 'r') as file:\n",
        "    source_lines = file.readlines()\n",
        "with open('../Dataset/writingPrompts/train.wp_target', 'r') as file:\n",
        "    target_lines = file.readlines()\n",
        "\n",
        "df_source = pd.DataFrame(source_lines, columns=['source'])\n",
        "df_target = pd.DataFrame(target_lines, columns=['target'])\n",
        "\n",
        "df_merged = pd.concat([df_source, df_target], axis=1)\n",
        "\n",
        "df_merged.to_json('../PreProcessedDataset/train.json', orient='records', lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6744cebf",
        "outputId": "b00e4ced-cc47-4bcf-a81a-7963a3e55052"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[ WP ] You 've finally managed to discover the...</td>\n",
              "      <td>So many times have I walked on ruins , the rem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[ WP ] The moon is actually a giant egg , and ...</td>\n",
              "      <td>-Week 18 aboard the Depth Reaver , Circa 2023-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[ WP ] You find a rip in time walking through ...</td>\n",
              "      <td>I was feckin ' sloshed , mate . First time I e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[ WP ] For years in your youth the same imagin...</td>\n",
              "      <td>“ No , no no no ... ” She backed up and turned...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[ WP ] You glance at your watch 10:34 am , rou...</td>\n",
              "      <td>There 's a magical moment between wakefulness ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              source  \\\n",
              "0  [ WP ] You 've finally managed to discover the...   \n",
              "1  [ WP ] The moon is actually a giant egg , and ...   \n",
              "2  [ WP ] You find a rip in time walking through ...   \n",
              "3  [ WP ] For years in your youth the same imagin...   \n",
              "4  [ WP ] You glance at your watch 10:34 am , rou...   \n",
              "\n",
              "                                              target  \n",
              "0  So many times have I walked on ruins , the rem...  \n",
              "1  -Week 18 aboard the Depth Reaver , Circa 2023-...  \n",
              "2  I was feckin ' sloshed , mate . First time I e...  \n",
              "3  “ No , no no no ... ” She backed up and turned...  \n",
              "4  There 's a magical moment between wakefulness ...  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df=pd.read_json('../PreProcessedDataset/train.json', lines=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "068d9500"
      },
      "outputs": [],
      "source": [
        "with open('../Dataset/writingPrompts/valid.wp_source', 'r') as file:\n",
        "    source_lines = file.readlines()\n",
        "with open('../Dataset/writingPrompts/valid.wp_target', 'r') as file:\n",
        "    target_lines = file.readlines()\n",
        "\n",
        "df_source = pd.DataFrame(source_lines, columns=['source'])\n",
        "df_target = pd.DataFrame(target_lines, columns=['target'])\n",
        "\n",
        "df_merged = pd.concat([df_source, df_target], axis=1)\n",
        "\n",
        "df_merged.to_json('../PreProcessedDataset/valid.json', orient='records', lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "444af794",
        "outputId": "9279e3f0-e5a7-455c-b1cd-fa8153ccab4c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[ WP ] Every person in the world undergoes a `...</td>\n",
              "      <td>Clancy Marguerian , 154 , private first class ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[ WP ] Space mining is on the rise . The Space...</td>\n",
              "      <td>„… and the little duckling will never be able ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[ WP ] `` I wo n't have time to explain all of...</td>\n",
              "      <td>I wo n't have the time to explain all of this ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[ CW ] Write about a song . Each sentence must...</td>\n",
              "      <td>* '' [ Sally ] ( https : //www.youtube.com/wat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[ EU ] You live in Skyrim . It is your job to ...</td>\n",
              "      <td>Light is a marvelous thing . It alone can turn...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              source  \\\n",
              "0  [ WP ] Every person in the world undergoes a `...   \n",
              "1  [ WP ] Space mining is on the rise . The Space...   \n",
              "2  [ WP ] `` I wo n't have time to explain all of...   \n",
              "3  [ CW ] Write about a song . Each sentence must...   \n",
              "4  [ EU ] You live in Skyrim . It is your job to ...   \n",
              "\n",
              "                                              target  \n",
              "0  Clancy Marguerian , 154 , private first class ...  \n",
              "1  „… and the little duckling will never be able ...  \n",
              "2  I wo n't have the time to explain all of this ...  \n",
              "3  * '' [ Sally ] ( https : //www.youtube.com/wat...  \n",
              "4  Light is a marvelous thing . It alone can turn...  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df=pd.read_json('../PreProcessedDataset/valid.json', lines=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In the above code we have taken the dataset from kaggle and stored it in json format in our github and also on our respective drives for future use\n",
        "**~by mukund**"
      ],
      "metadata": {
        "id": "Bnkq-uuAZRGV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Vi1BQjFWZ1g2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 2** - Loading the stored dataset and making it suitable for training purpose"
      ],
      "metadata": {
        "id": "JqLp-6alZnBj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dV03Dmwn5Wlw",
        "outputId": "b7c1fd9b-5ae7-43ed-9eae-ca6e473b7bb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "4DiTMSN2976s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json('/content/drive/MyDrive/PreProcessedDataset/train.json',lines = True)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "M--3C290-IH3",
        "outputId": "93bed3ee-eb4c-4789-e90a-6f6d672fabca",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   source  \\\n",
              "0       [ WP ] You 've finally managed to discover the...   \n",
              "1       [ WP ] The moon is actually a giant egg , and ...   \n",
              "2       [ WP ] You find a rip in time walking through ...   \n",
              "3       [ WP ] For years in your youth the same imagin...   \n",
              "4       [ WP ] You glance at your watch 10:34 am , rou...   \n",
              "...                                                   ...   \n",
              "272595  [ WP ] You wake up , extremely thirsty and dre...   \n",
              "272596  [ WP ] After many years , you finally decide t...   \n",
              "272597  [ WP ] In a world where people can only be kil...   \n",
              "272598  [ WP ] Use a lyric from a song , or even the w...   \n",
              "272599  [ CW ] [ PM ] Write your hero into a corner , ...   \n",
              "\n",
              "                                                   target  \n",
              "0       So many times have I walked on ruins , the rem...  \n",
              "1       -Week 18 aboard the Depth Reaver , Circa 2023-...  \n",
              "2       I was feckin ' sloshed , mate . First time I e...  \n",
              "3       “ No , no no no ... ” She backed up and turned...  \n",
              "4       There 's a magical moment between wakefulness ...  \n",
              "...                                                   ...  \n",
              "272595  `` He was a good man . '' <newline> <newline> ...  \n",
              "272596  The Envelope <newline> <newline> It 's been 23...  \n",
              "272597  17 people . Ive killed 17 people . I cant reme...  \n",
              "272598  > So make the best of this test and do n't ask...  \n",
              "272599  Bob dropped five of the Zeds , reloaded his Co...  \n",
              "\n",
              "[272600 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6da3da6c-4e51-423c-b689-778b695cdfe7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[ WP ] You 've finally managed to discover the...</td>\n",
              "      <td>So many times have I walked on ruins , the rem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[ WP ] The moon is actually a giant egg , and ...</td>\n",
              "      <td>-Week 18 aboard the Depth Reaver , Circa 2023-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[ WP ] You find a rip in time walking through ...</td>\n",
              "      <td>I was feckin ' sloshed , mate . First time I e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[ WP ] For years in your youth the same imagin...</td>\n",
              "      <td>“ No , no no no ... ” She backed up and turned...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[ WP ] You glance at your watch 10:34 am , rou...</td>\n",
              "      <td>There 's a magical moment between wakefulness ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272595</th>\n",
              "      <td>[ WP ] You wake up , extremely thirsty and dre...</td>\n",
              "      <td>`` He was a good man . '' &lt;newline&gt; &lt;newline&gt; ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272596</th>\n",
              "      <td>[ WP ] After many years , you finally decide t...</td>\n",
              "      <td>The Envelope &lt;newline&gt; &lt;newline&gt; It 's been 23...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272597</th>\n",
              "      <td>[ WP ] In a world where people can only be kil...</td>\n",
              "      <td>17 people . Ive killed 17 people . I cant reme...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272598</th>\n",
              "      <td>[ WP ] Use a lyric from a song , or even the w...</td>\n",
              "      <td>&gt; So make the best of this test and do n't ask...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272599</th>\n",
              "      <td>[ CW ] [ PM ] Write your hero into a corner , ...</td>\n",
              "      <td>Bob dropped five of the Zeds , reloaded his Co...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>272600 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6da3da6c-4e51-423c-b689-778b695cdfe7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6da3da6c-4e51-423c-b689-778b695cdfe7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6da3da6c-4e51-423c-b689-778b695cdfe7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0e143e22-2c4d-4d37-ad6b-d032ef904e7b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0e143e22-2c4d-4d37-ad6b-d032ef904e7b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0e143e22-2c4d-4d37-ad6b-d032ef904e7b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a9cf418b-3362-430f-a98a-fec51a505984\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a9cf418b-3362-430f-a98a-fec51a505984 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "NGJGhYD1bLCs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are merging the prompt and the essay column because while generating the model should treat them as a single continuous entity because intutively what the model does is predict the next token based on the previous tokens so the llms like chatgpt or deepseek effectively are just continuing your prompt and the prompt has to be included in the context window"
      ],
      "metadata": {
        "id": "cmPky6BZaIFt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "P1YVky5cbJt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['merged'] = df['source'] + \" \" + df['target']\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "QaJ5EpxV-vhX",
        "outputId": "787759c8-e1a2-4414-ef6f-61690c77f899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   source  \\\n",
              "0       [ WP ] You 've finally managed to discover the...   \n",
              "1       [ WP ] The moon is actually a giant egg , and ...   \n",
              "2       [ WP ] You find a rip in time walking through ...   \n",
              "3       [ WP ] For years in your youth the same imagin...   \n",
              "4       [ WP ] You glance at your watch 10:34 am , rou...   \n",
              "...                                                   ...   \n",
              "272595  [ WP ] You wake up , extremely thirsty and dre...   \n",
              "272596  [ WP ] After many years , you finally decide t...   \n",
              "272597  [ WP ] In a world where people can only be kil...   \n",
              "272598  [ WP ] Use a lyric from a song , or even the w...   \n",
              "272599  [ CW ] [ PM ] Write your hero into a corner , ...   \n",
              "\n",
              "                                                   target  \\\n",
              "0       So many times have I walked on ruins , the rem...   \n",
              "1       -Week 18 aboard the Depth Reaver , Circa 2023-...   \n",
              "2       I was feckin ' sloshed , mate . First time I e...   \n",
              "3       “ No , no no no ... ” She backed up and turned...   \n",
              "4       There 's a magical moment between wakefulness ...   \n",
              "...                                                   ...   \n",
              "272595  `` He was a good man . '' <newline> <newline> ...   \n",
              "272596  The Envelope <newline> <newline> It 's been 23...   \n",
              "272597  17 people . Ive killed 17 people . I cant reme...   \n",
              "272598  > So make the best of this test and do n't ask...   \n",
              "272599  Bob dropped five of the Zeds , reloaded his Co...   \n",
              "\n",
              "                                                   merged  \n",
              "0       [ WP ] You 've finally managed to discover the...  \n",
              "1       [ WP ] The moon is actually a giant egg , and ...  \n",
              "2       [ WP ] You find a rip in time walking through ...  \n",
              "3       [ WP ] For years in your youth the same imagin...  \n",
              "4       [ WP ] You glance at your watch 10:34 am , rou...  \n",
              "...                                                   ...  \n",
              "272595  [ WP ] You wake up , extremely thirsty and dre...  \n",
              "272596  [ WP ] After many years , you finally decide t...  \n",
              "272597  [ WP ] In a world where people can only be kil...  \n",
              "272598  [ WP ] Use a lyric from a song , or even the w...  \n",
              "272599  [ CW ] [ PM ] Write your hero into a corner , ...  \n",
              "\n",
              "[272600 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-27dc6640-cee9-45d3-9e18-45b2690b29bb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "      <th>merged</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[ WP ] You 've finally managed to discover the...</td>\n",
              "      <td>So many times have I walked on ruins , the rem...</td>\n",
              "      <td>[ WP ] You 've finally managed to discover the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[ WP ] The moon is actually a giant egg , and ...</td>\n",
              "      <td>-Week 18 aboard the Depth Reaver , Circa 2023-...</td>\n",
              "      <td>[ WP ] The moon is actually a giant egg , and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[ WP ] You find a rip in time walking through ...</td>\n",
              "      <td>I was feckin ' sloshed , mate . First time I e...</td>\n",
              "      <td>[ WP ] You find a rip in time walking through ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[ WP ] For years in your youth the same imagin...</td>\n",
              "      <td>“ No , no no no ... ” She backed up and turned...</td>\n",
              "      <td>[ WP ] For years in your youth the same imagin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[ WP ] You glance at your watch 10:34 am , rou...</td>\n",
              "      <td>There 's a magical moment between wakefulness ...</td>\n",
              "      <td>[ WP ] You glance at your watch 10:34 am , rou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272595</th>\n",
              "      <td>[ WP ] You wake up , extremely thirsty and dre...</td>\n",
              "      <td>`` He was a good man . '' &lt;newline&gt; &lt;newline&gt; ...</td>\n",
              "      <td>[ WP ] You wake up , extremely thirsty and dre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272596</th>\n",
              "      <td>[ WP ] After many years , you finally decide t...</td>\n",
              "      <td>The Envelope &lt;newline&gt; &lt;newline&gt; It 's been 23...</td>\n",
              "      <td>[ WP ] After many years , you finally decide t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272597</th>\n",
              "      <td>[ WP ] In a world where people can only be kil...</td>\n",
              "      <td>17 people . Ive killed 17 people . I cant reme...</td>\n",
              "      <td>[ WP ] In a world where people can only be kil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272598</th>\n",
              "      <td>[ WP ] Use a lyric from a song , or even the w...</td>\n",
              "      <td>&gt; So make the best of this test and do n't ask...</td>\n",
              "      <td>[ WP ] Use a lyric from a song , or even the w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272599</th>\n",
              "      <td>[ CW ] [ PM ] Write your hero into a corner , ...</td>\n",
              "      <td>Bob dropped five of the Zeds , reloaded his Co...</td>\n",
              "      <td>[ CW ] [ PM ] Write your hero into a corner , ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>272600 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27dc6640-cee9-45d3-9e18-45b2690b29bb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-27dc6640-cee9-45d3-9e18-45b2690b29bb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-27dc6640-cee9-45d3-9e18-45b2690b29bb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-da54d805-db71-44f5-9a53-33abc88d704e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-da54d805-db71-44f5-9a53-33abc88d704e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-da54d805-db71-44f5-9a53-33abc88d704e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4967fb98-482e-46ec-bef5-1cf9d139cd45\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4967fb98-482e-46ec-bef5-1cf9d139cd45 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "special_char = ' # '\n",
        "text = special_char.join(df['merged'].dropna().astype(str))\n",
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkWZE_y1CSYc",
        "outputId": "f54e86db-652f-498f-f5a6-f615284317bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "944467148"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "R5zNlbQHbN1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decreasing the size of our data because our session got crashed lol"
      ],
      "metadata": {
        "id": "o1mtAj7bawq6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Zxak7cyKbIHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ok = int(0.01*len(text))\n",
        "text = text[:ok]"
      ],
      "metadata": {
        "id": "I-56kZeeFPOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ok = int(0.01*len(text))\n",
        "text = text[:ok]"
      ],
      "metadata": {
        "id": "SOZ1MA-2bERn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_chars = set(text)\n",
        "print(unique_chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09j9vNX6C110",
        "outputId": "86762197-8e18-48b5-f454-82137891d9e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ê', 'F', 'o', '=', '!', 'è', 'р', 'ï', '،', '-', 'y', '6', 'ϐ', 'u', 'ل', '_', 'أ', '%', '\\u200b', '0', 'á', 'B', ';', '´', 't', 'В', '⊙', 'ö', 'Q', 'ë', '－', 'ð', 'ß', 'щ', 'D', 'е', '≥', ' ', '^', '«', '(', 'V', '―', 'а', '.', '×', 'ا', 'ت', 'Z', 'آ', '?', 'ы', ')', 'м', 'م', '…', 'с', 'т', 'ю', 'Y', 'ó', 'k', 'Э', '№', 'd', 'L', 'П', '❧', 'ь', '–', '”', '*', 'ب', 'c', '|', '\\x90', '$', 'a', 'о', '！', '’', 'r', 'n', 'T', 'R', 'ж', '4', 'E', 'm', '/', 'ջ', ',', '▦', 'О', 'Т', '9', '‽', '3', '\\x10', 'I', 'A', 'ه', '~', '@', 'ę', 'ä', 'п', 'ط', 'ø', '▶', 'خ', 'W', 'Ֆ', '\\\\', '\\x81', 'v', 'к', 'х', 'в', 'M', '®', 'س', '}', '5', '¡', 'g', '∞', '`', 'w', 'б', ']', '>', 'ذ', 'Ϡ', 'д', '{', 'л', 'ن', 'ك', '╬', '☂', 'Ö', 'f', '»', 'i', '2', 'q', 'ç', '£', '1', 'j', 'й', '◀', 'C', 'Δ', 'Д', 'e', 'h', '\\ufeff', '+', '。', '&', 'Ԭ', 'P', '[', 'ف', 'و', '÷', 'ج', 'z', 'Н', 'b', 'É', '#', 'ч', 'p', 'N', '‘', '<', 'غ', 'С', 'X', '\\n', 'H', '8', '，', 'x', 'º', '™', '“', 'J', 'ü', '7', 'ي', 'Л', 'Ч', 'π', 's', 'н', \"'\", 'и', 'ة', '—', 'ق', 'ã', 'ē', 'Р', ':', '°', 'G', '₪', 'у', 'ء', '؟', '♦', 'د', 'ض', 'з', 'ú', 'ر', 'S', 'U', 'Ϣ', 'إ', '„', 'é', 'K', 'ñ', 'O', 'l', '◕', 'г'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "dkN9U10obkVN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above we can see that the dataset contains many letters not from english language (Honestly i dont know where these chinese alphabets came from lol so lets remove them using simple regex :)"
      ],
      "metadata": {
        "id": "5FvtDvtEbGDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "V0YSliFvblNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "allowed_chars = \"a-zA-Z\\n,\\.! \"  # allowed: english letters, newline, comma, period, exclamation mark, and space\n",
        "allowed_chars_pattern = f\"[^{allowed_chars}]\"\n",
        "cleaned_text = re.sub(allowed_chars_pattern, '', text)\n"
      ],
      "metadata": {
        "id": "urCz7N-LDcz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(cleaned_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ia8XEJXlEUn8",
        "outputId": "d3408ab3-6777-48b6-b75f-b7cd9928abed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9087940"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_chars = set(cleaned_text)\n",
        "print(unique_chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ru2AkswEMDn",
        "outputId": "bcdd1783-75f9-4285-bb84-003bb366d83c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'z', 'Y', 'F', 'v', 'b', 'k', 'd', 'o', 'p', 'N', 'M', '!', 'L', 'X', '\\n', 'H', 'y', 'x', 'g', 'c', 'u', 'a', 'w', 'J', 'r', 'n', 's', 'T', 'R', 'B', 'f', 't', 'E', 'Q', 'm', 'i', 'q', 'D', ' ', ',', 'j', 'G', 'C', 'e', 'h', 'V', 'I', 'A', '.', 'S', 'U', 'Z', 'P', 'K', 'O', 'l', 'W'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "normal neural net\n"
      ],
      "metadata": {
        "id": "_arXysTjPJIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(set(cleaned_text))\n",
        "vocab_size = len(chars)\n",
        "chars\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQlD5p8a1FgQ",
        "outputId": "d7b3be76-9bd0-422a-baae-b0602fc56876",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " ' ',\n",
              " '!',\n",
              " ',',\n",
              " '.',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'W',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'Z',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5RjGQpmmbuS8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perfect!\n",
        "# Now its necessary to note that which entities are being selected by us as tokens since we know the LLMs nowdays use probably some 4-5 letters together as one token but in our case for simplicity we consider a single letter as a token which will save time while training  "
      ],
      "metadata": {
        "id": "Ott3SwoGbsqs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Note - We may increase the length of tokens in future for better results"
      ],
      "metadata": {
        "id": "g-UIZd-EcMZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "letter_to_number = {letter: idx for idx, letter in enumerate(chars)}\n",
        "encoded_text = [letter_to_number[char] for char in cleaned_text] # encoding the letters to numbers"
      ],
      "metadata": {
        "id": "49ucI9hx1Krs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "better way to encode\n"
      ],
      "metadata": {
        "id": "6A6rTK1Lc5B3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "E9QF7Cgn2Rlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n"
      ],
      "metadata": {
        "id": "MYvHhmGM4CHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.tensor(encode(cleaned_text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dniLNmv02SrF",
        "outputId": "78e9f35b-d5ce-4250-96f1-3cbfd8f4aed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([9087940]) torch.int64\n",
            "tensor([ 1, 27, 20,  1,  1, 29, 45, 51,  1, 52, 35,  1, 36, 39, 44, 31, 42, 42,\n",
            "        55,  1, 43, 31, 44, 31, 37, 35, 34,  1, 50, 45,  1, 34, 39, 49, 33, 45,\n",
            "        52, 35, 48,  1, 50, 38, 35,  1, 49, 35, 33, 48, 35, 50,  1, 50, 45,  1,\n",
            "        39, 43, 43, 45, 48, 50, 31, 42, 39, 50, 55,  1,  4,  1, 23, 51, 34, 34,\n",
            "        35, 44, 42, 55,  1,  3,  1,  8, 35, 31, 50, 38,  1, 31, 46, 46, 35, 31,\n",
            "        48, 49,  1, 32, 35, 36, 45, 48, 35,  1, 55, 45, 51,  1,  3,  1, 38, 31,\n",
            "        44, 34, 49,  1, 55, 45, 51,  1, 31,  1, 32, 51, 49, 39, 44, 35, 49, 49,\n",
            "         1, 33, 31, 48, 34,  1,  3,  1, 31, 44, 34,  1, 49, 31, 55, 49,  1,  3,\n",
            "         1,  1, 27, 38, 35, 44,  1, 55, 45, 51,  1, 48, 35, 31, 42, 39, 56, 35,\n",
            "         1, 42, 39, 52, 39, 44, 37,  1, 36, 45, 48, 35, 52, 35, 48,  1, 49, 51,\n",
            "        33, 41, 49,  1,  3,  1, 33, 31, 42, 42,  1, 50, 38, 39, 49,  1, 44, 51,\n",
            "        43, 32, 35, 48,  1,  3,  1, 13,  1, 52, 35,  1, 37, 45, 50,  1, 31,  1,\n",
            "        40, 45, 32,  1, 45, 36, 36, 35, 48,  1, 36, 45, 48,  1, 55, 45, 51,  1,\n",
            "         4,  1,  0,  1, 23, 45,  1, 43, 31, 44, 55,  1, 50, 39, 43, 35, 49,  1,\n",
            "        38, 31, 52, 35,  1, 13,  1, 53, 31, 42, 41, 35, 34,  1, 45, 44,  1, 48,\n",
            "        51, 39, 44, 49,  1,  3,  1, 50, 38, 35,  1, 48, 35, 43, 31, 39, 44, 39,\n",
            "        44, 37, 49,  1, 45, 36,  1, 46, 42, 31, 33, 35, 49,  1, 50, 38, 31, 50,\n",
            "         1, 13,  1, 42, 45, 52, 35, 34,  1, 31, 44, 34,  1, 37, 45, 50,  1, 51,\n",
            "        49, 35, 34,  1, 50, 45,  4,  4,  1,  5, 50,  1, 36, 39, 48, 49, 50,  1,\n",
            "        13,  1, 53, 31, 49,  1, 49, 33, 31, 48, 35, 34,  1,  3,  1, 35, 31, 33,\n",
            "        38,  1, 50, 39, 43, 35,  1, 13,  1, 33, 45, 51, 42, 34,  1, 36, 35, 35,\n",
            "        42,  1, 43, 55,  1, 33, 39, 50, 55,  1,  3,  1, 43, 55,  1, 33, 51, 48,\n",
            "        48, 35, 44, 50,  1, 37, 35, 44, 35, 48, 31, 50, 39, 45, 44,  1, 33, 45,\n",
            "        42, 42, 31, 46, 49, 35,  1,  3,  1, 32, 48, 35, 31, 41,  1, 39, 44, 50,\n",
            "        45,  1, 50, 38, 35,  1, 32, 42, 31, 33, 41,  1, 38, 45, 42, 35,  1, 50,\n",
            "        38, 31, 50,  1, 50, 38, 48, 39, 52, 35, 49,  1, 53, 39, 50, 38, 39, 44,\n",
            "         1, 39, 50,  1,  3,  1, 13,  1, 33, 45, 51, 42, 34,  1, 36, 35, 35, 42,\n",
            "         1, 38, 51, 43, 31, 44, 39, 50, 55,  1,  3,  1, 50, 38, 35,  1, 53, 31,\n",
            "        55,  1, 13,  1, 43,  1, 31, 32, 42, 35,  1, 50, 45,  1, 36, 35, 35, 42,\n",
            "         1, 43, 55,  1, 32, 45, 34, 55,  4,  4,  1,  5, 36, 50, 35, 48,  1, 31,\n",
            "         1, 36, 35, 53,  1, 38, 51, 44, 34, 48, 35, 34,  1, 55, 35, 31, 48, 49,\n",
            "         1,  3,  1, 50, 38, 35,  1, 46, 31, 50, 50, 35, 48, 44,  1, 32, 35, 33,\n",
            "        31, 43, 35,  1, 45, 32, 52, 39, 45, 51, 49,  1,  3,  1, 44, 45,  1, 42,\n",
            "        45, 44, 37, 35, 48,  1, 50, 38, 35,  1, 53, 31, 48,  1, 31, 44, 34,  1,\n",
            "        34, 31, 43, 31, 37, 35,  1, 50, 38, 31, 50,  1, 53, 45, 51, 42, 34,  1,\n",
            "        34, 35, 52, 31, 49, 50, 31, 50, 35,  1, 43, 35,  1, 45, 52, 35, 48,  1,\n",
            "        31, 44, 34,  1, 45, 52, 35, 48,  1, 31, 37, 31, 39, 44,  1, 39, 44,  1,\n",
            "        50, 38, 35,  1, 36, 31, 48,  1, 46, 31, 49, 50,  1, 53, 31, 49,  1, 35,\n",
            "        36, 36, 35, 33, 50, 39, 44, 37,  1, 43, 35,  1, 49, 45,  1, 34, 45, 43,\n",
            "        39, 44, 31, 44, 50, 42, 55,  1,  4,  1, 44, 35, 53, 42, 39, 44, 35,  1,\n",
            "        13, 50,  1, 49,  1, 36, 51, 44, 44, 55,  1,  3,  1, 32, 51, 50,  1, 13,\n",
            "         1, 36, 35, 42, 50,  1, 31, 49,  1, 39, 36,  1, 31, 36, 50, 35, 48,  1,\n",
            "        37, 31, 39, 44, 39, 44, 37,  1, 53, 38, 31, 50,  1, 13,  1, 34, 35, 49,\n",
            "        39, 48, 35, 34,  1, 49, 45,  1, 42, 45, 44, 37,  1,  3,  1, 53, 38, 31,\n",
            "        50,  1, 13,  1, 38, 31, 52, 35,  1, 42, 39, 52, 35, 34,  1, 36, 45, 48,\n",
            "         1, 43, 55,  1, 35, 44, 50, 39, 48, 35,  1, 42, 39, 36, 35,  1,  3,  1,\n",
            "        45, 44, 42, 55,  1, 50, 38, 35, 44,  1,  3,  1, 53, 38, 35, 44,  1, 13,\n",
            "         1, 31, 33, 38, 39, 35, 52, 35, 34,  1, 39, 43, 43, 45, 48, 50, 31, 42,\n",
            "        39, 50, 55,  1, 13,  1, 49, 50, 31, 48, 50, 35, 34,  1, 50, 48, 51, 42,\n",
            "        55,  1, 31, 37, 39, 44, 37,  1,  4,  1, 44, 35, 53, 42, 39, 44, 35,  1,\n",
            "        44, 35, 53, 42, 39, 44, 35,  1,  1, 53, 45, 48, 42, 34,  1, 53, 31, 48,\n",
            "        49,  1, 38, 31, 52, 35,  1, 46, 31, 49, 49, 35, 34,  1,  3,  1, 31, 44,\n",
            "        34,  1, 44, 45, 53,  1, 50, 38, 35, 55,  1, 36, 35, 35, 42,  1, 42, 39,\n",
            "        41, 35,  1, 31,  1, 49, 39, 43, 46, 42, 35,  1, 49, 39, 33, 41, 35, 44,\n",
            "        35, 49, 49,  1, 50, 38, 31, 50,  1, 53, 45, 51, 42, 34,  1, 46, 31, 49,\n",
            "        49,  1, 32, 55,  1, 35, 52, 35, 48, 55])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "nxjla7yG4M9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**credits~ Naman, Prashant**"
      ],
      "metadata": {
        "id": "0Q0D6mdFeA87"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "OZU5mE-7dvRy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NOW LETS START WITH THE MODELS**"
      ],
      "metadata": {
        "id": "m5XTQLjjdmJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SO our main objective is not only to make a resume level project but to learn along the way. So we dont want to directly jump to final step which would be fine tuning a pretrained becuase that is as easy as watching a yotube video and copying the code from net\n",
        "\n",
        "# Instead we want to familiarize ouselves with the history of machine learning how it started, what were the initial models that paved the way for the final boss i.e. transformers"
      ],
      "metadata": {
        "id": "zsl7hzQPdw8K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LETS BEGIN!**"
      ],
      "metadata": {
        "id": "YRghTtaBex-2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model 1** - bigram model"
      ],
      "metadata": {
        "id": "Vs_DNh-Ae4S8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview of the Bigram Model in NLP\n",
        "The bigram model is a type of statistical language model that estimates the probability of a word based solely on the immediately preceding word. This approach assumes that the likelihood of a word depends only on its direct predecessor, significantly simplifying the modeling of language compared to considering longer contexts. Despite this simplification, bigram models have proven useful in various natural language processing tasks such as speech recognition, text prediction, and machine translation.\n",
        "\n",
        "# The First Research Paper on Bigram Models\n",
        "One of the earliest and most influential works that laid the foundation for statistical language models—including bigram models—is Claude Shannon’s seminal paper \"A Mathematical Theory of Communication\" (1948)"
      ],
      "metadata": {
        "id": "k-zAGQGSe9fM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NOTE - below we have implemented a character level bigram model"
      ],
      "metadata": {
        "id": "vG7NG4K8fjPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size = 6 # how many independent sequences will we process in parallel?\n",
        "block_size = 16 # what is the maximum context length for predictions? will increase this later this is just for testing\n",
        "\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print('----')\n",
        "\n",
        "for b in range(batch_size): # batch dimension\n",
        "    for t in range(block_size): # time dimension\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OY2arQNw4Np7",
        "outputId": "df9d7829-e581-4f59-b22b-70c04fcad77e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "torch.Size([6, 16])\n",
            "tensor([[39, 44, 37,  1, 39, 50,  1, 51, 44, 50, 39, 42,  1, 50, 38, 35],\n",
            "        [55,  1,  4,  1,  1, 44, 35, 53, 42, 39, 44, 35,  1, 44, 35, 53],\n",
            "        [50, 38, 35,  1, 49, 50, 48, 35, 35, 50, 49,  1, 50, 38, 35,  1],\n",
            "        [55,  1,  4,  0,  1, 24, 38, 35,  1, 49, 46, 31, 48, 41, 42, 39],\n",
            "        [46, 42, 39, 35, 49,  1, 53, 39, 50, 38,  1, 31, 44, 37, 35, 48],\n",
            "        [34,  1, 33, 38, 35, 33, 41,  1, 36, 45, 48,  1, 55, 45, 51, 48]])\n",
            "targets:\n",
            "torch.Size([6, 16])\n",
            "tensor([[44, 37,  1, 39, 50,  1, 51, 44, 50, 39, 42,  1, 50, 38, 35,  1],\n",
            "        [ 1,  4,  1,  1, 44, 35, 53, 42, 39, 44, 35,  1, 44, 35, 53, 42],\n",
            "        [38, 35,  1, 49, 50, 48, 35, 35, 50, 49,  1, 50, 38, 35,  1, 31],\n",
            "        [ 1,  4,  0,  1, 24, 38, 35,  1, 49, 46, 31, 48, 41, 42, 39, 35],\n",
            "        [42, 39, 35, 49,  1, 53, 39, 50, 38,  1, 31, 44, 37, 35, 48,  1],\n",
            "        [ 1, 33, 38, 35, 33, 41,  1, 36, 45, 48,  1, 55, 45, 51, 48, 49]])\n",
            "----\n",
            "when input is [39] the target: 44\n",
            "when input is [39, 44] the target: 37\n",
            "when input is [39, 44, 37] the target: 1\n",
            "when input is [39, 44, 37, 1] the target: 39\n",
            "when input is [39, 44, 37, 1, 39] the target: 50\n",
            "when input is [39, 44, 37, 1, 39, 50] the target: 1\n",
            "when input is [39, 44, 37, 1, 39, 50, 1] the target: 51\n",
            "when input is [39, 44, 37, 1, 39, 50, 1, 51] the target: 44\n",
            "when input is [39, 44, 37, 1, 39, 50, 1, 51, 44] the target: 50\n",
            "when input is [39, 44, 37, 1, 39, 50, 1, 51, 44, 50] the target: 39\n",
            "when input is [39, 44, 37, 1, 39, 50, 1, 51, 44, 50, 39] the target: 42\n",
            "when input is [39, 44, 37, 1, 39, 50, 1, 51, 44, 50, 39, 42] the target: 1\n",
            "when input is [39, 44, 37, 1, 39, 50, 1, 51, 44, 50, 39, 42, 1] the target: 50\n",
            "when input is [39, 44, 37, 1, 39, 50, 1, 51, 44, 50, 39, 42, 1, 50] the target: 38\n",
            "when input is [39, 44, 37, 1, 39, 50, 1, 51, 44, 50, 39, 42, 1, 50, 38] the target: 35\n",
            "when input is [39, 44, 37, 1, 39, 50, 1, 51, 44, 50, 39, 42, 1, 50, 38, 35] the target: 1\n",
            "when input is [55] the target: 1\n",
            "when input is [55, 1] the target: 4\n",
            "when input is [55, 1, 4] the target: 1\n",
            "when input is [55, 1, 4, 1] the target: 1\n",
            "when input is [55, 1, 4, 1, 1] the target: 44\n",
            "when input is [55, 1, 4, 1, 1, 44] the target: 35\n",
            "when input is [55, 1, 4, 1, 1, 44, 35] the target: 53\n",
            "when input is [55, 1, 4, 1, 1, 44, 35, 53] the target: 42\n",
            "when input is [55, 1, 4, 1, 1, 44, 35, 53, 42] the target: 39\n",
            "when input is [55, 1, 4, 1, 1, 44, 35, 53, 42, 39] the target: 44\n",
            "when input is [55, 1, 4, 1, 1, 44, 35, 53, 42, 39, 44] the target: 35\n",
            "when input is [55, 1, 4, 1, 1, 44, 35, 53, 42, 39, 44, 35] the target: 1\n",
            "when input is [55, 1, 4, 1, 1, 44, 35, 53, 42, 39, 44, 35, 1] the target: 44\n",
            "when input is [55, 1, 4, 1, 1, 44, 35, 53, 42, 39, 44, 35, 1, 44] the target: 35\n",
            "when input is [55, 1, 4, 1, 1, 44, 35, 53, 42, 39, 44, 35, 1, 44, 35] the target: 53\n",
            "when input is [55, 1, 4, 1, 1, 44, 35, 53, 42, 39, 44, 35, 1, 44, 35, 53] the target: 42\n",
            "when input is [50] the target: 38\n",
            "when input is [50, 38] the target: 35\n",
            "when input is [50, 38, 35] the target: 1\n",
            "when input is [50, 38, 35, 1] the target: 49\n",
            "when input is [50, 38, 35, 1, 49] the target: 50\n",
            "when input is [50, 38, 35, 1, 49, 50] the target: 48\n",
            "when input is [50, 38, 35, 1, 49, 50, 48] the target: 35\n",
            "when input is [50, 38, 35, 1, 49, 50, 48, 35] the target: 35\n",
            "when input is [50, 38, 35, 1, 49, 50, 48, 35, 35] the target: 50\n",
            "when input is [50, 38, 35, 1, 49, 50, 48, 35, 35, 50] the target: 49\n",
            "when input is [50, 38, 35, 1, 49, 50, 48, 35, 35, 50, 49] the target: 1\n",
            "when input is [50, 38, 35, 1, 49, 50, 48, 35, 35, 50, 49, 1] the target: 50\n",
            "when input is [50, 38, 35, 1, 49, 50, 48, 35, 35, 50, 49, 1, 50] the target: 38\n",
            "when input is [50, 38, 35, 1, 49, 50, 48, 35, 35, 50, 49, 1, 50, 38] the target: 35\n",
            "when input is [50, 38, 35, 1, 49, 50, 48, 35, 35, 50, 49, 1, 50, 38, 35] the target: 1\n",
            "when input is [50, 38, 35, 1, 49, 50, 48, 35, 35, 50, 49, 1, 50, 38, 35, 1] the target: 31\n",
            "when input is [55] the target: 1\n",
            "when input is [55, 1] the target: 4\n",
            "when input is [55, 1, 4] the target: 0\n",
            "when input is [55, 1, 4, 0] the target: 1\n",
            "when input is [55, 1, 4, 0, 1] the target: 24\n",
            "when input is [55, 1, 4, 0, 1, 24] the target: 38\n",
            "when input is [55, 1, 4, 0, 1, 24, 38] the target: 35\n",
            "when input is [55, 1, 4, 0, 1, 24, 38, 35] the target: 1\n",
            "when input is [55, 1, 4, 0, 1, 24, 38, 35, 1] the target: 49\n",
            "when input is [55, 1, 4, 0, 1, 24, 38, 35, 1, 49] the target: 46\n",
            "when input is [55, 1, 4, 0, 1, 24, 38, 35, 1, 49, 46] the target: 31\n",
            "when input is [55, 1, 4, 0, 1, 24, 38, 35, 1, 49, 46, 31] the target: 48\n",
            "when input is [55, 1, 4, 0, 1, 24, 38, 35, 1, 49, 46, 31, 48] the target: 41\n",
            "when input is [55, 1, 4, 0, 1, 24, 38, 35, 1, 49, 46, 31, 48, 41] the target: 42\n",
            "when input is [55, 1, 4, 0, 1, 24, 38, 35, 1, 49, 46, 31, 48, 41, 42] the target: 39\n",
            "when input is [55, 1, 4, 0, 1, 24, 38, 35, 1, 49, 46, 31, 48, 41, 42, 39] the target: 35\n",
            "when input is [46] the target: 42\n",
            "when input is [46, 42] the target: 39\n",
            "when input is [46, 42, 39] the target: 35\n",
            "when input is [46, 42, 39, 35] the target: 49\n",
            "when input is [46, 42, 39, 35, 49] the target: 1\n",
            "when input is [46, 42, 39, 35, 49, 1] the target: 53\n",
            "when input is [46, 42, 39, 35, 49, 1, 53] the target: 39\n",
            "when input is [46, 42, 39, 35, 49, 1, 53, 39] the target: 50\n",
            "when input is [46, 42, 39, 35, 49, 1, 53, 39, 50] the target: 38\n",
            "when input is [46, 42, 39, 35, 49, 1, 53, 39, 50, 38] the target: 1\n",
            "when input is [46, 42, 39, 35, 49, 1, 53, 39, 50, 38, 1] the target: 31\n",
            "when input is [46, 42, 39, 35, 49, 1, 53, 39, 50, 38, 1, 31] the target: 44\n",
            "when input is [46, 42, 39, 35, 49, 1, 53, 39, 50, 38, 1, 31, 44] the target: 37\n",
            "when input is [46, 42, 39, 35, 49, 1, 53, 39, 50, 38, 1, 31, 44, 37] the target: 35\n",
            "when input is [46, 42, 39, 35, 49, 1, 53, 39, 50, 38, 1, 31, 44, 37, 35] the target: 48\n",
            "when input is [46, 42, 39, 35, 49, 1, 53, 39, 50, 38, 1, 31, 44, 37, 35, 48] the target: 1\n",
            "when input is [34] the target: 1\n",
            "when input is [34, 1] the target: 33\n",
            "when input is [34, 1, 33] the target: 38\n",
            "when input is [34, 1, 33, 38] the target: 35\n",
            "when input is [34, 1, 33, 38, 35] the target: 33\n",
            "when input is [34, 1, 33, 38, 35, 33] the target: 41\n",
            "when input is [34, 1, 33, 38, 35, 33, 41] the target: 1\n",
            "when input is [34, 1, 33, 38, 35, 33, 41, 1] the target: 36\n",
            "when input is [34, 1, 33, 38, 35, 33, 41, 1, 36] the target: 45\n",
            "when input is [34, 1, 33, 38, 35, 33, 41, 1, 36, 45] the target: 48\n",
            "when input is [34, 1, 33, 38, 35, 33, 41, 1, 36, 45, 48] the target: 1\n",
            "when input is [34, 1, 33, 38, 35, 33, 41, 1, 36, 45, 48, 1] the target: 55\n",
            "when input is [34, 1, 33, 38, 35, 33, 41, 1, 36, 45, 48, 1, 55] the target: 45\n",
            "when input is [34, 1, 33, 38, 35, 33, 41, 1, 36, 45, 48, 1, 55, 45] the target: 51\n",
            "when input is [34, 1, 33, 38, 35, 33, 41, 1, 36, 45, 48, 1, 55, 45, 51] the target: 48\n",
            "when input is [34, 1, 33, 38, 35, 33, 41, 1, 36, 45, 48, 1, 55, 45, 51, 48] the target: 49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "vocab_size = len(chars)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "\n",
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2SZRgej4nv8",
        "outputId": "22116f6f-facc-47c5-95c5-74052d010a74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([640, 57])\n",
            "tensor(4.5551, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Cbp,HZOccjxqerAiK\n",
            "wwVpBxbhuBr rXvaPywWhA\n",
            "nL\n",
            "rbqFSiytRjATRHP.cTxDnYVSQXZ.Q!YwLjDPV\n",
            "\n",
            "KBhmpNcpQChsCVXbX\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Bt2j9lO4gD6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aove is some random stuff generated by our intial logits before training"
      ],
      "metadata": {
        "id": "TxYwV4ptgGES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "lkYFfzz5gPwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "7PN4IqwJ4v9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "for steps in range(300):\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5Bu2SVy4_hY",
        "outputId": "389a836d-e2e3-4b05-a1fa-6f3b6f567ebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4821109771728516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgUkfIhm5LdS",
        "outputId": "de38dd2e-e36a-4f74-f30a-c57a933921f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " orTTho nXD wais h Uphaus t aGinewu s nUDf the bs toomonRS s aseXc!gFFUz sy gh  medsk Stpownd flyqu . trd Sh ben tperso cho tbjnthaneneryoaldeveL kindmZ\n",
            "waLurighanouinewlal wlercke , , veIAee douxtlzalamed athit ly t pOnRes vesk winedoud onte,T tKane  tMSaHEMye mle n d I . angeNGm reeleRYomou waro in  tasEfat, hweay  ,oNNMcawligho thedrechevozyDQ, owoutXYOvene Haca homutXert ,FAsasit leXke ckictame G s h toKpus . stThont ththenYe semulippe boANshe ar g eng ai miors OlllisheaZanTOn sqaghapaHithon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "KdZNXJLpgS0T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Above is the generation after training the bigram model\n",
        "# Our loss is 2.48 here which still prety high if we talk about a character level model but and as you can see it still generates some giberish but the ouput is more structured and you can also see word formation that insertion of spaces which wasnt seen in the random stuff generated above. This is a hint of progress\n",
        "# lets keep going"
      ],
      "metadata": {
        "id": "35Z6itcIgVAF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**credits - Naman and katta bhai**"
      ],
      "metadata": {
        "id": "Ze90fzg8g6S0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Main problem** - the bigram model only looks at the previous charcter for prediction so lets give the other characters some attention"
      ],
      "metadata": {
        "id": "wJxXb4LbhH0r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Note - here we are trying to make the historic models better using the 2017 paper **Attention is all you need**"
      ],
      "metadata": {
        "id": "84OYL_fdiS88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n"
      ],
      "metadata": {
        "id": "A7I1oC0Vnez8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 20 # how many independent sequences will we process in parallel?\n",
        "block_size = 32 # what is the maximum context length for predictions?\n",
        "max_iters = 5000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.0"
      ],
      "metadata": {
        "id": "wVL0O-k8k1ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "# super simple bigram model\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = BigramLanguageModel()\n",
        "m = model.to(device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# generate from the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnKGdVCAkr_9",
        "outputId": "24d37ed5-405f-48eb-9a73-2f6c2147903d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.208697 M parameters\n",
            "step 0: train loss 4.2872, val loss 4.2902\n",
            "step 100: train loss 2.4598, val loss 2.4526\n",
            "step 200: train loss 2.3310, val loss 2.3426\n",
            "step 300: train loss 2.2324, val loss 2.2336\n",
            "step 400: train loss 2.1669, val loss 2.1581\n",
            "step 500: train loss 2.0889, val loss 2.0983\n",
            "step 600: train loss 2.0325, val loss 2.0257\n",
            "step 700: train loss 1.9712, val loss 1.9892\n",
            "step 800: train loss 1.9455, val loss 1.9462\n",
            "step 900: train loss 1.9084, val loss 1.9122\n",
            "step 1000: train loss 1.8866, val loss 1.8823\n",
            "step 1100: train loss 1.8791, val loss 1.8564\n",
            "step 1200: train loss 1.8408, val loss 1.8550\n",
            "step 1300: train loss 1.8172, val loss 1.8178\n",
            "step 1400: train loss 1.8004, val loss 1.8152\n",
            "step 1500: train loss 1.7793, val loss 1.7898\n",
            "step 1600: train loss 1.7601, val loss 1.7778\n",
            "step 1700: train loss 1.7587, val loss 1.7673\n",
            "step 1800: train loss 1.7510, val loss 1.7493\n",
            "step 1900: train loss 1.7406, val loss 1.7478\n",
            "step 2000: train loss 1.7127, val loss 1.7279\n",
            "step 2100: train loss 1.7134, val loss 1.7160\n",
            "step 2200: train loss 1.7041, val loss 1.7140\n",
            "step 2300: train loss 1.6942, val loss 1.7043\n",
            "step 2400: train loss 1.7015, val loss 1.7080\n",
            "step 2500: train loss 1.6879, val loss 1.6932\n",
            "step 2600: train loss 1.6844, val loss 1.6691\n",
            "step 2700: train loss 1.6811, val loss 1.6774\n",
            "step 2800: train loss 1.6731, val loss 1.6737\n",
            "step 2900: train loss 1.6576, val loss 1.6676\n",
            "step 3000: train loss 1.6704, val loss 1.6823\n",
            "step 3100: train loss 1.6441, val loss 1.6608\n",
            "step 3200: train loss 1.6399, val loss 1.6475\n",
            "step 3300: train loss 1.6251, val loss 1.6451\n",
            "step 3400: train loss 1.6291, val loss 1.6349\n",
            "step 3500: train loss 1.6188, val loss 1.6178\n",
            "step 3600: train loss 1.6152, val loss 1.6285\n",
            "step 3700: train loss 1.6180, val loss 1.6260\n",
            "step 3800: train loss 1.6075, val loss 1.6106\n",
            "step 3900: train loss 1.6181, val loss 1.6191\n",
            "step 4000: train loss 1.6106, val loss 1.6102\n",
            "step 4100: train loss 1.5909, val loss 1.6107\n",
            "step 4200: train loss 1.5963, val loss 1.6072\n",
            "step 4300: train loss 1.5924, val loss 1.6037\n",
            "step 4400: train loss 1.5834, val loss 1.5957\n",
            "step 4500: train loss 1.5944, val loss 1.5930\n",
            "step 4600: train loss 1.5780, val loss 1.5849\n",
            "step 4700: train loss 1.6005, val loss 1.6031\n",
            "step 4800: train loss 1.5806, val loss 1.5803\n",
            "step 4900: train loss 1.5815, val loss 1.5774\n",
            "step 4999: train loss 1.5741, val loss 1.5945\n",
            "\n",
            " Tour get over people frozed to have I ll ones this streep seech would steepince bupon wack codes in his write .  That are teturance so with gardon seelf scare repearedure of have up were realifulitus  newline newline Man palan ge one of his bussed volacted about now drens , all roltypushermer for the tarling sea . And is there its write out life to their nathing  newline newline They seatily spets grebring into up . Anyworen his given .  newline newline  If hagded if ucicizen where I started his wants of here , world here get . newline newline As  I llooked of tempile off man in her getterioned strates of metheredimes up , we larts a estrasseridy ourser me  Night or a going arice back , your us them . He could next with the firsmen imagined for jascemented him . I head astays seem . I ve not it all a gears    newline newline Muck a refortesused arous stalls any were vespodenty time , they infterst on the colfures of once , and nowf tookaving my muff aword .  newline newline newline Haren is hand belood . The plowine ... Bast it was the wording from time to the rend to sunkers say off arler rrealt s will ret cilled utclies to me , yes with fall lin its any detoodations towards . And thousy one over in wheer three seep ship were knowlededanes , whikeris to know or far . It have lapped to perseliencels   Well Kellecorse trildne bordes in for the safeur , takes . Oher contarce traight . newline newline A lacker , youngerld down . I ve her all ejifral . Alvive the croar weast are your anto stearly .  HP what mitiaes ! Jon Yyou re lo maket out a treagished would detpects and to loose the have progting , agnesing al one the ells . Sudtely for , Korritifly   And you year . My anknyway . They eyes people grant him footer two left arming . newline newline  It s ty lost with weating your langs in her what housf there her sided , toward She hallwhater to there . I  dreal attonal to everytherd is a find terrecting up brilled to .  Why stoches in the well step has thoutak and th\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interesting, So we tried adding a multi attention head to our charcter level model and the results didnt disappoint\n",
        "# the loss has went down to 1.5 which is prety good also there is negligible divergence between train and val loss which is a good sign and shows there is no overfitting"
      ],
      "metadata": {
        "id": "joYmIlC2i3IT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O-y44alrkFkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Speaking of the ouput we can observe drastic improvement in terms that the text now resembles english language we can observe some legitimate words and in comparison to normal bigram it is very much improved"
      ],
      "metadata": {
        "id": "qBO8MLSbjXbC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem** - The bottleneck now is the token length so no matter how much we train the charcter level model it is quite difficult for it to generate a complete essay from letter level predictions\n",
        "# So Next step would be Switching to words and hoping for better results"
      ],
      "metadata": {
        "id": "KwYKnfnbjtqm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Credits - Naman,Nishant**"
      ],
      "metadata": {
        "id": "z9mJjr5LkHA8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "f_h738u6kVX1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "77FqARPmkWkb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model 2** - Multi Layer Perceptron (using words as tokens)"
      ],
      "metadata": {
        "id": "rtSE1e-PkKdd"
      }
    }
  ]
}